{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import scipy.fftpack\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the NN - a simple Multi Layer Perceptron with 3 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series prediction model\n",
    "def dnn_keras_tspred_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.sigmoid,\n",
    "                       input_shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(32, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(8, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(1)\n",
    "  ])\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = 4000\n",
    "num_test_data = 1000\n",
    "timestep = 0.1\n",
    "tm =  np.arange(0, (num_train_data+num_test_data)*timestep, timestep)\n",
    "#The original signal\n",
    "y = np.sin(tm) + np.sin(tm*np.pi/2) + np.sin(tm*(-3*np.pi/2))\n",
    "# y = np.sin(tm)\n",
    "\n",
    "SNR = 10\n",
    "# SNR = 30\n",
    "# The noise signal\n",
    "ypn = y + np.random.normal(0,10**(-SNR/20),len(y))\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(tm[0:100],y[0:100], label='Original Signal')\n",
    "ax.plot(tm[0:100],ypn[0:100], label='Noisy Signal')\n",
    "ax.set_title('Signals amptitude')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train_data and train_labels\n",
    "dnn_numinputs = 64\n",
    "num_train_batch = 0\n",
    "train_data = []\n",
    "for k in range(num_train_data-dnn_numinputs-1):\n",
    "  train_data = np.concatenate((train_data,ypn[k:k+dnn_numinputs]))\n",
    "  num_train_batch = num_train_batch + 1\n",
    "train_data = np.reshape(train_data, (num_train_batch,dnn_numinputs))\n",
    "train_labels = y[dnn_numinputs:num_train_batch+dnn_numinputs]\n",
    "\n",
    "print(train_data.shape, train_labels.shape, y.shape, ypn.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader()\n",
    "\n",
    "model = dnn_keras_tspred_model()\n",
    "\n",
    "EPOCHS = 100\n",
    "strt_time = datetime.datetime.now()\n",
    "history = model.fit(train_data, train_labels, epochs=EPOCHS,\n",
    "                  validation_split=0.2, verbose=0,\n",
    "                  callbacks=[])\n",
    "curr_time = datetime.datetime.now()\n",
    "timedelta = curr_time - strt_time\n",
    "dnn_train_time = timedelta.total_seconds()\n",
    "print(\"DNN training done. Time elapsed: \", timedelta.total_seconds(), \"s\")\n",
    "plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test how well DNN predicts now\n",
    "num_test_batch = 0\n",
    "strt_idx = num_train_batch\n",
    "test_data=[]\n",
    "for k in range(strt_idx, strt_idx+num_test_data-dnn_numinputs-1):\n",
    "  test_data = np.concatenate((test_data,ypn[k:k+dnn_numinputs]));\n",
    "  num_test_batch = num_test_batch + 1\n",
    "test_data = np.reshape(test_data, (num_test_batch, dnn_numinputs))\n",
    "test_labels = y[strt_idx+dnn_numinputs:strt_idx+num_test_batch+dnn_numinputs]\n",
    "\n",
    "print(test_data.shape, test_labels.shape)\n",
    "\n",
    "\n",
    "dnn_predictions = model.predict(test_data).flatten()\n",
    "keras_dnn_err = test_labels - dnn_predictions\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(dnn_predictions[0:100], label='DNN predictions')\n",
    "ax.plot(test_labels[0:100], label='Targets')\n",
    "ax.set_title('DNN vs target')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least Mean Squares (LMS) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1000\n",
    "L = 64\n",
    "yrlms = np.zeros(M+L)\n",
    "m, c = np.zeros(M+L), np.zeros(M+L)\n",
    "#wn = np.random.normal(0,1,L)\n",
    "wn = np.zeros(L)\n",
    "print(wn.shape, yrlms.shape, y.shape)\n",
    "mu = 0.005\n",
    "for k in range(L,M+L):\n",
    "  yrlms[k] = np.dot(ypn[k-L:k],wn)\n",
    "  e = ypn[k]- yrlms[k]\n",
    "  wn=wn+(mu*ypn[k-L:k]*e)\n",
    "\n",
    "print(yrlms.shape)\n",
    "\n",
    "# Solve y = mx + c => y = Ap , A = [[x 1]] & p = [[m], [c]]\n",
    "A = np.zeros(M+L)\n",
    "for k in range(L,M+L):\n",
    "  A = np.vstack([y[k-L:k], np.ones(len(y[k-L:k]))]).T\n",
    "  # print(A.shape, y[k-L:k].shape)\n",
    "  m[k], c[k] = np.linalg.lstsq(A, ypn[k-L:k], rcond=None)[0]\n",
    "\n",
    "def prediction(x, m, c):\n",
    "  return m*x + c\n",
    "\n",
    "preds = prediction(y[0:M+L], m, c)\n",
    "print(preds.shape)\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(preds[600:700], label='Regression prediction')\n",
    "ax.plot(y[600:700], label='Targets')\n",
    "ax.set_title('Regression vs Original')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Prediction results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_err = dnn_predictions - test_labels\n",
    "# lms_err = yrlms[0:M] - y[0:M]\n",
    "lms_err = preds[0:M] - y[0:M]\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(dnn_err, label='DNN error')\n",
    "ax.plot(lms_err, label='Regression error')\n",
    "ax.set_title('Error plots')\n",
    "ax.legend()\n",
    "dnn_mse = 10*np.log10(np.mean(pow(np.abs(dnn_err),2)))\n",
    "dnn_sigpow = 10*np.log10(np.mean(pow(np.abs(test_labels),2)))\n",
    "lms_mse = 10*np.log10(np.mean(pow(np.abs(lms_err[200:M]),2)))\n",
    "lms_sigpow = 10*np.log10(np.mean(pow(np.abs(y[200:M]),2)))\n",
    "\n",
    "#print(dnn_mse, dnn_sigpow, lms_mse, lms_sigpow)\n",
    "print(\"Neural network SNR:\", dnn_sigpow - dnn_mse)\n",
    "print(\"LMS Prediction SNR:\", lms_sigpow - lms_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Fourier Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 point FFT\n",
    "N = 64\n",
    "\n",
    "# Using the same noisy signal used for LMS\n",
    "yf = scipy.fftpack.fft(ypn[0:N])\n",
    "\n",
    "# Let us remove noise, easy to do at the FFT output\n",
    "y_clean = np.zeros(N,dtype=complex)\n",
    "cidx = np.where(np.abs(yf)>(N*0.2/2))[0]\n",
    "y_clean[cidx]=yf[cidx]\n",
    "\n",
    "# 0 to Fs/2, Fs = 1/Ts\n",
    "# xf = np.linspace(0.0, 1.0/(2*timestep), int(N/2))\n",
    "xf = scipy.fftpack.fftfreq(N, timestep)[:N // 2]\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "# Plotting only from 0 to Fs/2\n",
    "plt.plot(xf, 2.0/N * np.abs(y_clean[:N//2]),'r')\n",
    "plt.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_keras_fft_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(NFFT*2, activation=tf.nn.relu,\n",
    "                       input_shape=(train_data.shape[1],)),\n",
    "    keras.layers.Dense(NFFT*2, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(NFFT*2)\n",
    "  ])\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae']) \n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the DNN for 16 point FFT\n",
    "NFFT = 64\n",
    "num_train_batch = 1\n",
    "num_batches = 10000\n",
    "train_data = np.random.normal(0,1,(num_batches, NFFT*2))\n",
    "train_labels = np.random.normal(0,1,(num_batches, NFFT*2))\n",
    "model = dnn_keras_fft_model()\n",
    "for k in range(num_train_batch):\n",
    "  for el in range(num_batches):\n",
    "    fftin = train_data[el,0::2] + 1j*train_data[el,1::2]\n",
    "    train_labels[el,0::2]=scipy.fftpack.fft(fftin).real\n",
    "    train_labels[el,1::2]=scipy.fftpack.fft(fftin).imag\n",
    "  EPOCHS = 100\n",
    "  strt_time = datetime.datetime.now()\n",
    "  history = model.fit(train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[])\n",
    "  curr_time = datetime.datetime.now()\n",
    "  timedelta = curr_time - strt_time\n",
    "  dnn_train_time = timedelta.total_seconds()\n",
    "  print(\"DNN training done. Time elapsed: \", timedelta.total_seconds(), \"s\")\n",
    "  plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "            label = 'Val loss')\n",
    "  plt.show()\n",
    "  \n",
    "  train_data = np.random.normal(0,1,(num_batches, NFFT*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftin = np.zeros((1,2*NFFT))\n",
    "fftin[:,0::2]=ypn[0:NFFT]\n",
    "fftout = model.predict(fftin).flatten()\n",
    "fftout = fftout[0::2] + 1j*fftout[1::2]\n",
    "plt.plot(xf, 2.0/NFFT * np.abs(fftout[0:NFFT//2]))\n",
    "plt.plot(xf, 2.0/N * np.abs(yf[:N//2]),'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare FFT & NN Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.random.normal(0,1,(1000, NFFT*2))\n",
    "test_labels = np.random.normal(0,1,(1000, NFFT*2))\n",
    "for el in range(1000):\n",
    "  fftin = test_data[el,0::2] + 1j*test_data[el,1::2]\n",
    "  test_labels[el,0::2]=scipy.fftpack.fft(fftin).real\n",
    "  test_labels[el,1::2]=scipy.fftpack.fft(fftin).imag\n",
    "\n",
    "dnn_out = model.predict(test_data).flatten()\n",
    "keras_dnn_err = test_labels.flatten() - dnn_out\n",
    "plt.plot(keras_dnn_err)\n",
    "plt.show()\n",
    "\n",
    "dnn_fft_mse = 10*np.log10(np.mean(pow(np.abs(keras_dnn_err),2)))\n",
    "labels_sigpow = 10*np.log10(np.mean(pow(np.abs(test_labels.flatten()),2)))\n",
    "print(\"Neural Network SNR compare to SciPy FFT: \", labels_sigpow - dnn_fft_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e18625b61c31662b6d6247c999ddff17b68c950594959749fd3c45e96c7402d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
